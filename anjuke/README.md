anjuke_spider

爬取安居客租房链接下所有的租房信息。
1.使用随机ua，保存为csv文件
2.爬取频率过高会被安居客封ip数小时。
---应对：1）使用代理ip池，但是免费的好多没法用，放弃。
         2）调整DOWNLOAD_DELAY时间，左右不大。
		 3）多个机器，爬取不同页面。
		 
---选择处理办法：
		使用Google cache，找到爬取页面对应的cache url即可
		
ps：不管爬虫选取的是什么网站，爬取网站上的数据只是为了练习python和分析下数据。坚决不对网站进行恶意的请求。